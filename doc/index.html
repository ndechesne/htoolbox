<h1>HBackup documentation</h1>

<h2>Introduction</h2>

<p>This is a backup program. The name HBackup has been chosen because of the
way data is stored: based on the file hash (&agrave; la git). It basically
copies files from given directories on client computers into a folder
mounted locally. It is of course incremental, and is designed with speed and
low memory usage in mind.</p>

<h2>Why yet another backup program?</h2>

<ul>
<li>Because I wanted a dead-simple configuration: one file with less than 15
different keywords. It is also possible to reference a file on the client,
so users can have their own backup configuration for their machine.</li>

<li>Because I did not want to install anything on the clients: NFS for UNIX and
SMB for Windows are all you need. The basic idea is: if I can mount it in a
non-iteractive way, I can back it up.</li>

<li>Because I wanted something geared towards what I do: software development. This system can easily be made to recognise
version-controlled directories to optimise backup choices: why re-backup files
that are on a server somewhere, itself with its own backup system?</li>
</ul>

<p>On top of parsers, the system provides a powerful filtering system. The
filtering system is generic and used two-fold:</p>
<ul>
<li>to select files to be ignored (i.e. not backed up)</li>
<li>to select files to be compressed</li>
</ul>

<h2>Contents</h2>

<p>The pages below will help you configure the backup system:</p>

<ul>
<li><a href="server.html">server</a></li>
<li><a href="client.html">client</a></li>
<li><a href="user-mode.html">user-mode</a></li>
<li><a href="filters.html">filters</a></li>
<li><a href="parsers.html">parsers</a></li>
</ul>

<p>The is also a <a href="implementation.html">page about the
implementation</a> (under construction).</p>